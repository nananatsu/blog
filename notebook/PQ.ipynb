{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1wpuiTotNABT+9EWouFEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nananatsu/blog/blob/master/PQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "准备测试数据"
      ],
      "metadata": {
        "id": "_c0D6I-_wF8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YxtYY93ev_iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8e0a24-6821-4c0c-e1c1-6ac0c7b6b8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Archive:  /content/drive/MyDrive/train_data/baike2018qa.zip\n",
            "  inflating: mydata/baike_qa_train.json  \n",
            "  inflating: mydata/baike_qa_valid.json  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!mkdir -p mydata\n",
        "!unzip /content/drive/MyDrive/train_data/baike2018qa.zip -d mydata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install numpy pandas scipy sentence-transformers torch faiss-gpu"
      ],
      "metadata": {
        "id": "pX_NUsN2wCGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_json('./mydata/baike_qa_train.json', lines=True, nrows=5000)\n",
        "\n",
        "sentences = data['title']"
      ],
      "metadata": {
        "id": "BUwVYf42wDvo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('DMetaSoul/sbert-chinese-general-v2')\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "sentence_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7EyP8-XjqT",
        "outputId": "168d0e2c-4ace-430a-f1ee-d7f1df5762e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "量化是将输入值从大集合（通常是连续的）映射到较小集合（通常具有有限数量元素），舍入（用更短、更简单、更明确的近似值进行替换）和截断（限制小数点右边的位数）是典型的量化过程，量化构成了所有有损压缩算法的核心。输入值与量化值间的差异称为量化误差，执行量化的设备或算法功能称为量化器。"
      ],
      "metadata": {
        "id": "TDyNI9rwkGDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PQ（乘积量化）通过将向量空间分解为低位子空间的笛卡尔积，每个子空间独自进行量化，这样一个向量能够被子空间量化后的索引组成的短编码表示，两个向量间的L2距离可以通过量化后的编码进行估计。\n"
      ],
      "metadata": {
        "id": "lT2EKprr22w9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义$q$是一个量化函数，将D维向量$x \\in \\mathbb{R}^D$映射为向量$q(x) \\in C $，$C = \\{c_i;i \\in I \\}$是一个大小为k的编码簿， 其中$I = 0 ... k-1$是一个有限的索引集合，$c_i$被称为质心。\n",
        "\n",
        "将所有映射到同一索引$i$的向量划分为一个单元(Voronoi cell) $V_i$：\n",
        "\n",
        "$V_i \\mathop{=}\\limits^{Δ} \\{x ∈ \\mathbb{R}^D : q(x) = c_i \\}$，\n",
        "\n",
        "量化器的$k$个单元是向量空间$\\mathbb{R}^D$的一个分区，在同一个单元$V_i$中向量都被质心$c_i$重构（用质心$C_i$表示单元$V_i$特征），量化器的好坏可以用输入向量与其再现值$q(x)$间的均方误差(MSE)来度量，使用$d(x,y) = \\Vert x -y \\Vert$表示两个向量间的L2距离，$p(x)$表示随机变量$X$的概率分布函数，则其均方误差为：\n",
        "\n",
        "$MSE(q) = \\mathbb{E}_X[d(q(x),x)^2] = ∫ p(x) d(q(x),x)^2 dx$\n"
      ],
      "metadata": {
        "id": "htNST1Zh99y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "x = sentence_embeddings[0]\n",
        "\n",
        "D = len(x)\n",
        "k = 2**8"
      ],
      "metadata": {
        "id": "eRbua0HbZtDe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "# 找到最近的质心\n",
        "def nearest(x, c, k):\n",
        "  min_distance = 9e9\n",
        "  idx = -1\n",
        "\n",
        "  # 找到L2距离的质心\n",
        "  for i in range(k):\n",
        "    l2_distance = distance.euclidean(x,c[i])\n",
        "    if l2_distance < min_distance:\n",
        "      idx = i\n",
        "      min_distance = l2_distance\n",
        "  return idx"
      ],
      "metadata": {
        "id": "w8-M5k81cLC6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 随机建立质心创建编码簿\n",
        "c = []\n",
        "for i in range(k):\n",
        "  c_i =  [randint(0, 9) for _ in range(D)]\n",
        "  c.append(c_i)\n",
        "\n",
        "# 测试向量x与其量化值c_i的均方误差\n",
        "i = nearest(x, c, k)\n",
        "mse = (np.square(x - c[i])).mean()\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ADKjgoclqU",
        "outputId": "0be22599-db6c-4159-8f1b-b59e68f47586"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.871004007228425"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "为使量化器最优，需要满足劳埃德(Lloyd)最优条件：\n",
        "- 向量$x$需要被量化到最近的质心，以L2距离作为距离函数则：$q(x) = arg \\: \\mathop{min}\\limits_{c_i \\in C} d(x,c_i)$，这样单元间被超平面划分。\n",
        "- 质心必须是Voronoi单元中的向量的期望：$c_i = \\mathbb{E}_X[x|i] = \\int_{V_i} p(x) x dx$，劳埃德量化器迭代分配向量到质心并从分配后的向量集合中重新估计质心。"
      ],
      "metadata": {
        "id": "9LXzaoHGIbGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 迭代估计质心\n",
        "def lloyd_estimate(cells,c,embeddings,k,ite_num):\n",
        "  # 按新质心重新分配向量\n",
        "  for i,v in enumerate(embeddings):\n",
        "    idx = nearest(v,c,k)\n",
        "    cells[idx].append(i)\n",
        "\n",
        "  end = True\n",
        "  # 遍历各单元，计算单元中向量的期望作为质心\n",
        "  for i,cell in enumerate(cells):\n",
        "    if len(cell) > 0:\n",
        "      cell_vectors = []\n",
        "      for idx in cell:\n",
        "        cell_vectors.append(embeddings[idx])\n",
        "      centroid = np.asarray(cell_vectors).mean(axis=0)\n",
        "\n",
        "      if np.all(c[i] != centroid):\n",
        "        c[i] = centroid\n",
        "        end = end & False\n",
        "      cells[i] = []\n",
        "\n",
        "  ite_num-=1\n",
        "  # 当所有单元质心不在变化或进行10次迭代后返回\n",
        "  if end or ite_num <= 0 :\n",
        "    return\n",
        "  lloyd_estimate(cells,c,embeddings,k,ite_num)"
      ],
      "metadata": {
        "id": "0sQKDWhGJA7k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 重新估计质心\n",
        "c = np.random.randint(1, int(sentence_embeddings.max()+1), (k, D))\n",
        "cells = []\n",
        "for i in range(k):\n",
        "  cells.append([])\n",
        "\n",
        "lloyd_estimate(cells,c,sentence_embeddings[:4000],k,10)"
      ],
      "metadata": {
        "id": "VFm0MdzRjXpm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机检查向量与其量化值得均方误差\n",
        "mses = []\n",
        "for i in range(10):\n",
        "  idx = randint(4000, len(sentence_embeddings))\n",
        "  x = sentence_embeddings[idx]\n",
        "  c_idx = nearest(x,c,k)\n",
        "  mse = (np.square(x - c[c_idx])).mean()\n",
        "  mses.append(mse)\n",
        "mses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDqAdGtUOP2r",
        "outputId": "57e68fa2-ff57-47c2-92e6-1043f66a8c7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4213924281641214,\n",
              " 0.44701967442937934,\n",
              " 0.40987476818263135,\n",
              " 0.3347929217051524,\n",
              " 0.3945715719573131,\n",
              " 0.3933250410274553,\n",
              " 0.4046597370237311,\n",
              " 0.4163056436451407,\n",
              " 0.386595268688162,\n",
              " 0.4268464239636341]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "当有大量向量时，我们需要增加质心数量以减小均方误差，假设要将一个128维的向量将其量化为64位的编码，则需要$k=2^{64}$个质心与编码对应，每个质心为128维浮点数，需要$D × k = 2^{64} \\times 128$个浮点值来存储质心，量化器的训练复杂度是$k=2^{64}$的好几倍，这样在内存进行向量量化是不可能的，乘积量化通过允许选择进行联合量化的组件数量来解决存储及复杂性问题。"
      ],
      "metadata": {
        "id": "kVl436rENvfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "将输入向量$x$切分为$m$个不同的子向量$u_j, 1 ≤ j ≤ m$，子向量维度$D^* = D/m$，D是m的倍数，将子向量用m个不同量化器分别进行量化，$q_j$是第j个子向量使用的量化器，通过子量化器$q_j$关联索引集合$I_j$，对应到编码簿$C_j$及相应的质心$c_{j,i}$\n",
        "\n",
        "$ \\underbrace{x_1,...,x_{D^*},}_{u_1(x)} ...,\\underbrace{x_{D-D^*+1},...,x_D}_{u_m(x)} → q_1(u_1(x)),...,q_m(u_m(x))$"
      ],
      "metadata": {
        "id": "trwLVNwgzU5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "乘积量器再现值由索引集合的笛卡尔积$I = I_1 × ... × I_m $确定，相应的编码簿为$C = C_1 × ... × C_m$，集合中的元素对应向量经m个子量化器处理后的质心，假设所有的子量化器有着有限个数$k^*$个再现值，总质心数$k = (k^*)^m$"
      ],
      "metadata": {
        "id": "_A6V5zxS4vIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 子向量数量\n",
        "m = 8\n",
        "assert D % m == 0\n",
        "assert k % m == 0\n",
        "\n",
        "# 子向量纬度\n",
        "D_ = int(D/m)\n",
        "# 子编码簿大小\n",
        "k_ = 256\n",
        "k = k_*m"
      ],
      "metadata": {
        "id": "ssl-QNBldiEl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割子向量\n",
        "embeddings_split = sentence_embeddings[:4000].reshape(-1, m, D_)\n",
        "# 生成随机编码簿\n",
        "c_s = np.random.randint(1, int(sentence_embeddings.max()+1), (m, k_, D_))\n",
        "\n",
        "cells = []\n",
        "# 训练量化器\n",
        "for i in range(m):\n",
        "  cells_i = []\n",
        "  for j in range(k_):\n",
        "    cells_i.append([])\n",
        "  lloyd_estimate(cells_i,c_s[i],embeddings_split[:,i],k_,10)\n",
        "  cells.append(cells_i)"
      ],
      "metadata": {
        "id": "dmUk1nSUsaep"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quantization(v):\n",
        "  u = v.reshape(m,D_)\n",
        "  ids = []\n",
        "  for j in range(m):\n",
        "    idx = nearest(u[j], c_s[j], k_)\n",
        "    ids.append(idx)\n",
        "  return ids"
      ],
      "metadata": {
        "id": "-1Jc_nIpbME3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机检查向量与其量化值得均方误差\n",
        "mses = []\n",
        "for i in range(10):\n",
        "  v = sentence_embeddings[randint(4000, len(sentence_embeddings))]\n",
        "  ids = quantization(v)\n",
        "  q = []\n",
        "  for j,u in enumerate(ids):\n",
        "    q.extend(c_s[j][u])\n",
        "  mse = (np.square(v - q)).mean()\n",
        "  mses.append(mse)\n",
        "mses\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2frgibsV-8W",
        "outputId": "5c583ed8-0c26-408e-c833-1d7acd164cff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38222087722969444,\n",
              " 0.35351928153797624,\n",
              " 0.4083119303245983,\n",
              " 0.36553835592335915,\n",
              " 0.4584325647498803,\n",
              " 0.41869153930207464,\n",
              " 0.4386770316646695,\n",
              " 0.39155881868569337,\n",
              " 0.39578527771000305,\n",
              " 0.3789821753973439]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "乘积量化的优势在于通过几个小的质心集合生成一个大的质心集合，只需要存储子量化器对应的$m \\times k^*$个质心，总计$mk^*D^*$个浮点值，即相应内存使用及复杂性为$mk^*D^* = k^{(1/m)}D $，相较其他量化方法k-means、HKM，PQ能够在内存中对较大k值得向量进行索引。"
      ],
      "metadata": {
        "id": "hy8iRHP7-13X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在向量中连续的元素在结构上通常是相关的，最好使用同一个子量化器进行量化，由于子向量空间是正交的，量化器的均方误差可以表示为：\n",
        "\n",
        "$MSE(q) = \\mathop{\\sum}\\limits_{j} MSE(q_j) $\n",
        "\n",
        "更高的$k^*$会造成更高的计算复杂度，更大的内存占用，通常$k^* = 256,m = 8$是一个合理的选择。"
      ],
      "metadata": {
        "id": "iBe2E8qoUG8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "有两种方法来计算查询向量与量化后向量的距离\n",
        "- 对称距离计算(SDC)：将查询向量也进行量化，计算量化后向量间的距离\n",
        "- 非对称距离计算(ADC)：不对查询向量量化，直接计算距离"
      ],
      "metadata": {
        "id": "i14PT9Bpb044"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_res = []\n",
        "for i,v in enumerate(sentence_embeddings):\n",
        "  ids = quantization(v)\n",
        "  quantization_res.append(ids)"
      ],
      "metadata": {
        "id": "bigd7sTRgl8y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qi = randint(4000, len(sentence_embeddings))\n",
        "qv = sentence_embeddings[qi]\n",
        "q_ids = quantization(qv)\n",
        "\n",
        "all_dist = []\n",
        "for i,ids in enumerate(quantization_res):\n",
        "  dist = 0\n",
        "  for j,id in enumerate(ids):\n",
        "    dist+=distance.euclidean(c_s[j][id], c_s[j][q_ids[j]])\n",
        "  all_dist.append((dist,i))"
      ],
      "metadata": {
        "id": "5c1ITcs0RgMq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_dist.sort()\n",
        "\n",
        "print('查询:', sentences[qi])\n",
        "for d,idx in all_dist[:5]:\n",
        "  print('   L2距离:',d,'匹配:',sentences[idx] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQxLc5pzqiWm",
        "outputId": "4168b724-7d38-468b-9fc2-6a5ec5fee1e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "查询: 怎样才能安全删除硬盘中的无用文件？ \n",
            "   L2距离: 0.0 匹配: 我下边的全是白的还有地图是么也看不见? \n",
            "   L2距离: 0.0 匹配: 怎么看出款项已经到账？我怎样才能知道一笔款项是否已经到了公司的帐 \n",
            "   L2距离: 0.0 匹配: 月球上总共有多少座环形山 \n",
            "   L2距离: 0.0 匹配: 怎样才能安全删除硬盘中的无用文件？ \n",
            "   L2距离: 0.0 匹配: 红斑狼疮的发病率高吗？请问红斑狼疮是不是一种少见的病？ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qvs = qv.reshape(m, D_)\n",
        "all_dist_adc = []\n",
        "for i,ids in enumerate(quantization_res):\n",
        "  dist = 0\n",
        "  for j,id in enumerate(ids):\n",
        "    dist+=distance.euclidean(c_s[j][id], qvs[j])\n",
        "  all_dist_adc.append((dist,i))"
      ],
      "metadata": {
        "id": "tI-m8jnwlr99"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_dist_adc.sort()\n",
        "\n",
        "print('查询:', sentences[qi])\n",
        "for d,idx in all_dist_adc[:5]:\n",
        "  print('   L2距离:',d,'匹配:',sentences[idx] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8t5dr6ov5H3",
        "outputId": "28aab6b1-b0f5-4045-8377-3e7ba8ca70b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "查询: 怎样才能安全删除硬盘中的无用文件？ \n",
            "   L2距离: 51.58162599842743 匹配: 我下边的全是白的还有地图是么也看不见? \n",
            "   L2距离: 51.58162599842743 匹配: 怎么看出款项已经到账？我怎样才能知道一笔款项是否已经到了公司的帐 \n",
            "   L2距离: 51.58162599842743 匹配: 月球上总共有多少座环形山 \n",
            "   L2距离: 51.58162599842743 匹配: 怎样才能安全删除硬盘中的无用文件？ \n",
            "   L2距离: 51.58162599842743 匹配: 红斑狼疮的发病率高吗？请问红斑狼疮是不是一种少见的病？ \n"
          ]
        }
      ]
    }
  ]
}