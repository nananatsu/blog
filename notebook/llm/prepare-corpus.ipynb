{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:12:58.910861Z",
     "iopub.status.busy": "2025-07-04T08:12:58.910631Z",
     "iopub.status.idle": "2025-07-04T08:13:05.976843Z",
     "shell.execute_reply": "2025-07-04T08:13:05.975969Z",
     "shell.execute_reply.started": "2025-07-04T08:12:58.910831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-04T08:13:05.978011Z",
     "iopub.status.busy": "2025-07-04T08:13:05.977766Z",
     "iopub.status.idle": "2025-07-04T08:13:10.701785Z",
     "shell.execute_reply": "2025-07-04T08:13:10.700889Z",
     "shell.execute_reply.started": "2025-07-04T08:13:05.977991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, AlbertModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:13:10.704201Z",
     "iopub.status.busy": "2025-07-04T08:13:10.703726Z",
     "iopub.status.idle": "2025-07-04T08:13:10.722566Z",
     "shell.execute_reply": "2025-07-04T08:13:10.721554Z",
     "shell.execute_reply.started": "2025-07-04T08:13:10.704168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model, tokenizer, device, batch_size=32):\n",
    "    \"\"\"批量处理获取文本向量\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        # 移除标注信息，只保留制表符前的原始文本\n",
    "        batch_texts = [text.split('\\t')[0] for text in batch_texts]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "def spherical_mean(vectors, device=\"cuda\"):\n",
    "    # 将数据转移到 GPU\n",
    "    vectors_gpu = torch.from_numpy(vectors).to(device)\n",
    "    \n",
    "    # 初始估计使用向量和的归一化\n",
    "    center = torch.sum(vectors_gpu, dim=0)\n",
    "    center = center / torch.norm(center)\n",
    "    \n",
    "    max_iter = 100\n",
    "    tolerance = 1e-7\n",
    "    prev_center = None\n",
    "    \n",
    "    # 迭代优化以找到真正的球面质心\n",
    "    for _ in range(max_iter):\n",
    "        if prev_center is not None:\n",
    "            # 检查收敛\n",
    "            if torch.abs(1 - torch.dot(center, prev_center)) < tolerance:\n",
    "                break\n",
    "                \n",
    "        prev_center = center.clone()\n",
    "        \n",
    "        # 计算每个向量到当前中心的测地线距离的梯度\n",
    "        dots = torch.matmul(vectors_gpu, center)  # 批量计算点积\n",
    "        outer = dots.unsqueeze(1) * center.unsqueeze(0)  # 批量外积\n",
    "        tangent_vectors = vectors_gpu - outer\n",
    "        mean_direction = torch.mean(tangent_vectors, dim=0)\n",
    "        \n",
    "        # 如果梯度太小，说明已经收敛\n",
    "        if torch.norm(mean_direction) < tolerance:\n",
    "            break\n",
    "            \n",
    "        # 沿测地线更新中心\n",
    "        new_center = center + mean_direction\n",
    "        center = new_center / torch.norm(new_center)\n",
    "    \n",
    "    # 将结果转回 CPU\n",
    "    return center.cpu().numpy()\n",
    "\n",
    "def select_diverse_samples_faiss(embeddings,texts, target_size, device=\"cuda\"):\n",
    "    \"\"\"使用 FAISS 加速样本选择,支持 GPU 加速\"\"\"\n",
    "    import faiss\n",
    "    \n",
    "    # 检查是否可以使用 GPU\n",
    "    use_gpu = device == \"cuda\" and faiss.get_num_gpus() > 0\n",
    "    \n",
    "    def create_index(vectors):\n",
    "        \"\"\"创建新的索引\"\"\"\n",
    "        d = vectors.shape[1]\n",
    "        if use_gpu:\n",
    "            res = faiss.StandardGpuResources()\n",
    "            config = faiss.GpuIndexFlatConfig()\n",
    "            config.device = 0\n",
    "            config.useFloat16 = True\n",
    "            index = faiss.GpuIndexFlatIP(res, d, config)\n",
    "        else:\n",
    "            index = faiss.IndexFlatIP(d)\n",
    "        \n",
    "        # 添加向量到索引（向量已经在外部归一化）\n",
    "        batch_size = 50000\n",
    "        for i in range(0, len(vectors), batch_size):\n",
    "            batch = vectors[i:i + batch_size]\n",
    "            index.add(batch)\n",
    "            \n",
    "        return index\n",
    "    \n",
    "    # 预处理：对所有向量进行归一化\n",
    "    embeddings = embeddings.astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    \n",
    "    # 选择初始点\n",
    "    # initial_idx = np.random.randint(len(embeddings))\n",
    "    initial_idx = 0\n",
    "    print(f\"起始向量 { initial_idx } 原始文本 { texts[initial_idx] }\")\n",
    "    selected_indices = [initial_idx]\n",
    "    selected_mask = np.zeros(len(embeddings), dtype=bool)\n",
    "    selected_mask[initial_idx] = True\n",
    "    \n",
    "    # 搜索参数\n",
    "    rebuild_interval = 500  # 每500个样本重建一次索引\n",
    "    initial_k = 100\n",
    "    k_step = 100\n",
    "    max_k = min(1000, len(embeddings))\n",
    "    max_attempts = 5\n",
    "    \n",
    "    # 初始化索引和映射\n",
    "    index = None\n",
    "    index_map = {}\n",
    "    \n",
    "    with tqdm(total=target_size-1, desc=\"选择多样化样本\") as pbar:\n",
    "        while len(selected_indices) < target_size:\n",
    "            try:\n",
    "                # 每当选中rebuild_interval个样本时重建索引\n",
    "                if len(selected_indices) % rebuild_interval == 0 or index is None:\n",
    "                    # 清理旧索引\n",
    "                    if index is not None and use_gpu:\n",
    "                        del index\n",
    "                        torch.cuda.empty_cache()\n",
    "                    \n",
    "                    # 获取未选择的样本索引\n",
    "                    unselected = np.where(~selected_mask)[0]\n",
    "                    if len(unselected) == 0:\n",
    "                        print(\"所有点都已被选择\")\n",
    "                        break\n",
    "                        \n",
    "                    # 创建索引映射关系\n",
    "                    index_map = {i: idx for i, idx in enumerate(unselected)}\n",
    "                    # 创建新的索引（使用已归一化的向量）\n",
    "                    index = create_index(embeddings[unselected])\n",
    "                \n",
    "                # 计算已选向量的球面质心\n",
    "                selected_vectors = embeddings[selected_indices]\n",
    "                center = spherical_mean(selected_vectors, device)\n",
    "                \n",
    "                # 重整形并确保仍然归一化\n",
    "                center = center.reshape(1, -1).astype('float32')\n",
    "                \n",
    "                # 动态搜索策略\n",
    "                current_k = initial_k\n",
    "                attempts = 0\n",
    "                found = False\n",
    "                \n",
    "                while not found and attempts < max_attempts:\n",
    "                    # 使用向量取反来搜索最远的点\n",
    "                    D, I = index.search(-center, current_k)\n",
    "                    \n",
    "                    # 将局部索引映射回原始索引\n",
    "                    # original_indices = [index_map[idx] for idx in I[0]]\n",
    "                    \n",
    "                    # 尝试找到未选择的点\n",
    "                    for i,idx in enumerate(I[0]):\n",
    "                        orig_idx = index_map[idx]\n",
    "                        if not selected_mask[orig_idx]:\n",
    "                            # print(f\"选择向量: {orig_idx} 原始文本 { texts[orig_idx] } 距离: {D[0][i]} \")\n",
    "                            # 打印样本前后距离\n",
    "                            # print(f\"向量前后向量距离: { D[0][i-1] if i > 0 else 'None'}  {D[0][i+1] if i < len(I[0]) - 1 else 'None'}\")\n",
    "\n",
    "                            selected_indices.append(orig_idx)\n",
    "                            selected_mask[orig_idx] = True\n",
    "                            pbar.update(1)\n",
    "                            found = True\n",
    "                            break\n",
    "                    \n",
    "                    if not found:\n",
    "                        current_k = min(current_k + k_step, max_k)\n",
    "                        attempts += 1\n",
    "                \n",
    "                # 如果多次尝试后仍未找到点，随机选择一个未选择的点\n",
    "                if not found:\n",
    "                    unselected = np.where(~selected_mask)[0]\n",
    "                    if len(unselected) > 0:\n",
    "                        random_idx = np.random.choice(unselected)\n",
    "                        selected_indices.append(random_idx)\n",
    "                        selected_mask[random_idx] = True\n",
    "                        print(f\"随机选择一个未选择的点 {random_idx}\")\n",
    "                        pbar.update(1)\n",
    "                    else:\n",
    "                        print(\"所有点都已被选择\")\n",
    "                        break\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"处理时出错: {e}\")\n",
    "                if use_gpu:\n",
    "                    torch.cuda.empty_cache()\n",
    "                continue\n",
    "    \n",
    "    # 清理最终资源\n",
    "    if use_gpu and index is not None:\n",
    "        del index\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:13:10.726026Z",
     "iopub.status.busy": "2025-07-04T08:13:10.725727Z",
     "iopub.status.idle": "2025-07-04T08:13:12.397108Z",
     "shell.execute_reply": "2025-07-04T08:13:12.396419Z",
     "shell.execute_reply.started": "2025-07-04T08:13:10.725995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"voidful/albert_chinese_large\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T08:13:12.431881Z",
     "iopub.status.busy": "2025-07-04T08:13:12.431679Z",
     "iopub.status.idle": "2025-07-04T08:14:01.001080Z",
     "shell.execute_reply": "2025-07-04T08:14:01.000130Z",
     "shell.execute_reply.started": "2025-07-04T08:13:12.431855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_translation_corpus(corpus_path):\n",
    "    \"\"\"加载翻译语料库文件\"\"\"\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        return data['pairs']\n",
    "\n",
    "translation_pairs = load_translation_corpus(\"./translation_corpus.json\")\n",
    "\n",
    "# 提取中文文本并生成向量\n",
    "chinese_texts = [pair[1] for pair in translation_pairs]\n",
    "embeddings = get_embeddings(chinese_texts, model, tokenizer, device)\n",
    "\n",
    "# 选择训练集大小\n",
    "train_size = int(len(translation_pairs) * 0.7)\n",
    "# 使用 FAISS 选择多样化样本\n",
    "selected_indices = select_diverse_samples_faiss(embeddings,chinese_texts, train_size, device=str(device))\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_pairs = [translation_pairs[i] for i in selected_indices]\n",
    "val_pairs = [pair for i, pair in enumerate(translation_pairs) if i not in selected_indices]\n",
    "    \n",
    "# 准备输出数据\n",
    "result = {\n",
    "    \"train\": train_pairs,\n",
    "    \"validation\": val_pairs,\n",
    "}\n",
    "\n",
    "# 保存结果\n",
    "with open(\"translation_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6269030,
     "sourceId": 12369831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
